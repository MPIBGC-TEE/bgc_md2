{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8cf759c",
   "metadata": {},
   "source": [
    "# Comparison with Oâ€™Sullivan et al. (2022)\n",
    "<a href=\" https://doi.org/10.1038/s41467-022-32416-8\">https://doi.org/10.1038/s41467-022-32416-8</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0437967c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "jupyter:\n",
       "  jupytext:\n",
       "    text_representation:\n",
       "      extension: .md\n",
       "      format_name: markdown\n",
       "      format_version: '1.3'\n",
       "      jupytext_version: 1.13.6\n",
       "  kernelspec:\n",
       "    display_name: Python 3 (ipykernel)\n",
       "    language: python\n",
       "    name: python3\n",
       "---\n",
       "\n",
       "<!-- #region -->\n",
       "### Traceability analysis  \n",
       "\n",
       "#### Outline\n",
       "The traceability analysis defines several diagnostic variables using as much algebraic structure of the mass balance equation as is available.\n",
       "Not all diagnostic variables are possible for all compartmental models. \n",
       "\n",
       "We chose here to introduce the diagnostic variables not all at once but rather in the order of decreasing generality.\n",
       "\n",
       "The first diagnostic variables are available for all compartmental models and need no additional assumptions. \n",
       "In the later parts of this section we then assume to be able to identify more and more specific terms in the mass balance equation and use those to derive and trace ever more specific diagnostics.\n",
       "Thus the very first part is valid for all models but how many of the later parts are applicable to a specific model  depends on how much we know about it.  \n",
       "\n",
       "\n",
       "#### Derivation of the matrix decomposition \n",
       "Compartmental models (well mixed mass balanced) can be written in as an ordinary differential equation in matrix form that relates the momentary value of the (time) derivative $\\frac{d X}{d t}$ of an yet unknown function $X$ to the momentary value of $X$ itself.   \n",
       "$$\n",
       "\\frac{d X}{d t}= I(X,t) + \\tilde{M}(X,t) X \\quad (1)   \n",
       "$$ \n",
       "where $X$ is the statevector representing the pool contents, $\\tilde{M}$ the \"Compartmental matrix\" and $I$ the input vector.\n",
       "In Yiqi's group equation (1) is usually written with the negative Compartmental Matrix $M=-\\tilde{M}$ \n",
       "\n",
       "$$\n",
       "\\frac{d X}{d t}= I(X,t) - M(X,t) X \\quad (2)   \n",
       "$$ \n",
       "\n",
       "Together with a startvalue $X_0$ it constitutes an \"initial value problem\" (ivp) which can be solved numerically by moving step by step forward in time.\n",
       "\n",
       "Note: \n",
       "\n",
       "It is mathematical standard notation to use $X$ in the *formulation* of the ivp (representing the momentary value) althoug *after we have solved it* the solution is expressed as function of time $X(t)$. This avoids confusion since everything appering with arguments is recognizable as explicitly calculable *before* we have solved the ivp.\n",
       "\n",
       "The system is \"nonautonomous\" (if they depend on time $t$) and \"nonlinear\" if the dependent on $X$.\n",
       "It is always possible to factorize $M(X,t)$ into a product $M=A(X,t) K(X,t)$ where $K$ is a  diagonal matrix.\n",
       "and $I=B(t)*u(t)$ where $u$ is a scalar.\n",
       "Using these we arrive at \n",
       "$$\n",
       "\\frac{d X}{d t}=B(X,t) u(X,t) - A(X,t) K(X,t) X   \n",
       "$$\n",
       "\n",
       "##### Linearity assumption\n",
       "If we assume the model to be linear and nonautonomous the dependency on $X$ vanishes and we have\n",
       "\n",
       "$$\n",
       "\\frac{d X}{d t}= A(t) K(t) X + B(t) u(t) . \n",
       "$$\n",
       "\n",
       "##### Factorizability  assumption\n",
       "Although this is not possible in general in many published models the nonautonous part  can be further localized into a diagonal matrix $\\xi(t)$ so that we can achieve constant $A$ and $K$ which allows more specific interpretation.\n",
       "\n",
       "$$\n",
       "\\frac{d X}{d t}= B(t)u(t) - A \\xi(t) K X \n",
       "$$\n",
       "\n",
       "##### Factorizability of $\\xi$ assumption \n",
       "In some cases we can resolve $\\xi$ further.\n",
       "$$\n",
       "\\frac{d X}{d t}= B(t)u(t) - A \\xi_{temp}(t) \\xi_{mois}(t) K X  \n",
       "$$\n",
       "\n",
       "#### Definition of diagnostic variables\n",
       "\n",
       "##### Storage capacity $X_c$ and storage potential $X_p$\n",
       "These variables can be defined for any compartmental system and do not require either linearity nor factorizability. \n",
       "We can rearrange eq. $(1)$ and give names to the two summands. \n",
       "$$\n",
       "X = M^{-1}(X,t) \\left(I(X,t)- \\frac{d X}{d t} \\right) \\\\ \n",
       "  = \\underbrace{M^{-1}(X,t)I(X,t)}_{X_c} - \\underbrace{M^{-1}(X,t) \\frac{d X}{d t} }_{X_p} \\\\\n",
       "  = X_c - X_p\n",
       "$$\n",
       "Note:\n",
       "This is not to be read as a recipe to compute $X$.\n",
       "The equation becomes a bit clearer if we adapt the nomenclature to express that we *have solved the ivp* and know its solution $X(t)$  \n",
       "and therefore also  the derivative $\\frac{d X}{d t}=I(X(t),t) - M(X(t),t) X(t) =\\dot{X}(t)$ \n",
       "By substituting the solution $X(t)$ we get the recipes to compute:\n",
       "$$\n",
       "\\dot{X}(t) = I(X(t),t) - M(X(t),t) X \\\\\n",
       "X_c(t) = X(t)-X_p(t) \\\\ \n",
       "X_p(t) = M^{-1}(X(t),t)I(X,t) \\\\ \n",
       "$$\n",
       "we see that all the ingredients become explicit functions of time.   \n",
       "Since all values are taken at the same time $t$ we can drop the time dependence\n",
       "in the notation and write an equation we can use in the iterator.\n",
       "$$\n",
       "\\dot{X} = I - M X \\\\\n",
       "X_c = X + X_p \\\\ \n",
       "X_p = M^{-1}I  \\\\ \n",
       "$$\n",
       "\n",
       "##### Residence time\n",
       "The influx $I$ can always be written as $I=b u$ where the scalar $u=\\sum_{k=1\\dots n} I_k$  and the dimensionless vector $b=I/u$ where $\\sum_{k=1\\dots n} b_k =1$.\n",
       "Assumimg that the pool contents (the components of $X$)  have dimension $mass$ we can infer from eq. (1) that $M$ has dimension $\\frac{1}{time}$.\n",
       "The components of the (inverse) matrix $M^{-1}$ have therefore dimension $time$. Accordingly the product $RT= M^{-1} b$ is a vector of the same shape as $X$  whose components have dimesion $time$.\n",
       "In the context of the Traceability Framework $RT$ is therefore called *residence time*.\n",
       "\n",
       "Notes on nomenclature: \n",
       "1. The term *residence time* is not universally used with the same connotation outside the context of the *Traceability Analysis*.\n",
       "\n",
       "1. It is not *the time of residence* of the particles in the system for the following reasons:\n",
       "    1. In well mixed systems particles can reside in a pool for different times from zero to infinity.\n",
       "    1. You could compute the mean of these times over all particles exiting a pool, but even then the result is in general not equal to the above mentioned $rt$.\n",
       "    1. The mean residence time would only coincide with the definition above if the system was in equilibrium (which it clearly is not as e.g $NPP(t)$ shows.)\n",
       "    1. The origin of the term is probably most easily understood as the generalization of a one dimensional rate equation $\\frac{d}{dt} x = m x + u$ \n",
       "       If $r$ and $u$ are constant then the mean residence time is $rt= m^{-1}$. If we start with the rate as property of the model the *residence time* \n",
       "       can be defined as the inverse of this rate. The above definition is the generalization of this simple relationship to matrices and vectors.\n",
       "       The matrix $M^{-1}$ takes the role of the number $\\frac{1}{m}$ . In the context of the *Traceability Analysis* $M^{-1}$ is called *Chasing Time*. \n",
       "\n",
       "<!-- #endregion -->\n",
       "\n",
       "```python\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(Markdown(\"TracebilityText.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baa8c39",
   "metadata": {},
   "source": [
    "### Loading required packages  and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "038fffa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from functools import lru_cache\n",
    "import general_helpers as gh\n",
    "from bgc_md2.resolve.mvars import (\n",
    "    CompartmentalMatrix,\n",
    "    InputTuple,\n",
    "    StateVariableTuple\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e574995b",
   "metadata": {},
   "source": [
    "### Selecting models to compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d45f81",
   "metadata": {},
   "source": [
    "### Loading TRENDY data and model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d04d9f9",
   "metadata": {},
   "source": [
    "### Plots of traceable components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f1065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_t_val=1\n",
    "model_names_test={\n",
    "    \"yz_jules\": \"JULES\",\n",
    "    \"kv_visit2\": \"VISIT\",\n",
    "}\n",
    "model_folders_test=[(k) for k in model_names_test]\n",
    "test_arg_list_test=gh.get_test_arg_list(model_folders_test)\n",
    "\n",
    "model_cols={\n",
    "    \"yz_jules\": \"blue\",\n",
    "    \"kv_visit2\": \"orange\",\n",
    "    \"jon_yib\": \"green\",\n",
    "    \"kv_ft_dlem\": \"red\",\n",
    "    \"Aneesh_SDGVM\":\"yellow\",\n",
    "    \"cj_isam\": \"purple\",\n",
    "    \"bian_ibis2\":\"magenta\",\n",
    "    \"ORCHIDEE-V2\":\"teal\",\n",
    "}\n",
    "\n",
    "add_cols={\n",
    "    #\"yz_jules\": \"red\",\n",
    "    \"kv_visit2\": \"green\",\n",
    "#     \"jon_yib\": \"green\",\n",
    "#     \"kv_ft_dlem\": \"red\",\n",
    "#     \"Aneesh_SDGVM\":\"yellow\",\n",
    "#     \"cj_isam\": \"purple\",\n",
    "#     \"bian_ibis2\":\"magenta\",\n",
    "#     \"ORCHIDEE-V2\":\"teal\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec4da376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_x_xc_trendy(\n",
    "    model_names,  # dictionary (folder name : model name)\n",
    "    test_arg_list,  # a list of test_args from all models involved\n",
    "    delta_t_val,  # model time step\n",
    "    model_cols,  # dictionary (folder name :color)\n",
    "    add_cols,\n",
    "    part,  # 0<part<1 to plot only a part of the whole timeling, e.g. 1 (whole timeline) or 0.1 (10%)\n",
    "    averaging,  # number of iterator steps over which to average results. 1 for no averaging\n",
    "    overlap=True,  # compute overlapping timeframe or plot whole duration for all models\n",
    "):\n",
    "    if (part < 0) | (part > 1):\n",
    "        raise Exception(\n",
    "            \"Invalid partitioning in plot_components_combined: use part between 0 and 1\"\n",
    "        )\n",
    "    model_folders = [(k) for k in model_names]\n",
    "    fig = plt.figure(figsize=(17, 8))\n",
    "    ax = fig.subplots(1, 1)\n",
    "    k = 0\n",
    "    for mf in model_folders:\n",
    "        itr = gh.traceability_iterator_instance(mf, test_arg_list[k], delta_t_val)\n",
    "        if overlap == True:\n",
    "            start_min, stop_max = gh.min_max_index(\n",
    "                test_arg_list[k],\n",
    "                delta_t_val,\n",
    "                *gh.t_min_tmax_overlap(test_arg_list, delta_t_val)\n",
    "            )\n",
    "        else:\n",
    "            start_min, stop_max = gh.min_max_index(\n",
    "                test_arg_list[k],\n",
    "                delta_t_val,\n",
    "                *gh.t_min_tmax_full(test_arg_list, delta_t_val)\n",
    "            )\n",
    "        # if we do not want the whole interval but look at a smaller part to observe the dynamics\n",
    "        start, stop = int(stop_max - (stop_max - start_min) * part), stop_max\n",
    "        times = (\n",
    "            gh.times_in_days_aD(test_arg_list[k], delta_t_val)[start:stop]\n",
    "            / gh.days_per_year()\n",
    "        )\n",
    "        vals = itr[start:stop]\n",
    "        # print(\"vals.x\")\n",
    "        # print(vals.x[0:240])\n",
    "        \n",
    "        ############## method from O'Sallivan et al. (2022)\n",
    "        cVeg_trendy=test_arg_list[k].svs.cVeg\n",
    "        if model_names[mf]==\"VISIT\":\n",
    "            cSoil_trendy=test_arg_list[k].svs.cLitter+test_arg_list[k].svs.cSoil\n",
    "        else:\n",
    "            cSoil_trendy=test_arg_list[k].svs.cSoil\n",
    "        rh_trendy=test_arg_list[k].svs.rh\n",
    "        npp_trendy=test_arg_list[k].dvs.npp\n",
    "        #npp_trendy_yearly=npp_sum(npp_trendy)\n",
    "        \n",
    "        delta_cVeg=np.zeros_like(cVeg_trendy)\n",
    "        for i in range (len(cVeg_trendy)-1):\n",
    "            delta_cVeg[i]=cVeg_trendy[i+1]-cVeg_trendy[i]\n",
    "    \n",
    "        delta_cSoil=np.zeros_like(cSoil_trendy)\n",
    "        for i in range (len(cSoil_trendy)-1):\n",
    "            delta_cSoil[i]=cSoil_trendy[i+1]-cSoil_trendy[i]    \n",
    "    \n",
    "        tau_v=cVeg_trendy/(npp_trendy-delta_cVeg)\n",
    "        X_c_v_trendy=tau_v*npp_trendy\n",
    "        #X_c_v_trendy_yearly=gh.avg_timeline(X_c_v_trendy,12)\n",
    "\n",
    "        f_vs=delta_cSoil+rh_trendy\n",
    "\n",
    "        tau_s=cSoil_trendy/rh_trendy\n",
    "        X_c_s_trendy=f_vs*tau_s\n",
    "        #X_c_s_trendy_yearly=gh.avg_timeline(X_c_s_trendy,12)\n",
    "\n",
    "        X_trendy_total=(cVeg_trendy+cSoil_trendy)[start//averaging//delta_t_val:stop//averaging//delta_t_val]#*148940000*1000000*0.000000000001\n",
    "        X_c_trendy_total=(X_c_v_trendy+X_c_s_trendy)[start//averaging//delta_t_val:stop//averaging//delta_t_val]#*148940000*1000000*0.000000000001 \n",
    "        u_trendy=npp_trendy[start//averaging//delta_t_val:stop//averaging//delta_t_val]\n",
    "        tau_trendy=(tau_v+tau_s)[start//averaging//delta_t_val:stop//averaging//delta_t_val]\n",
    "#         print(str(mf)+\": \"+str(X_c_trendy_total.shape)+\" ; \"+str(X_trendy_total.shape))\n",
    "#         print (\"start: \"+str(start)+\" stop: \"+str(stop))\n",
    "#         print (tau_trendy)\n",
    "#         print (vals.rt)\n",
    "        ###################\n",
    "        ax.plot(\n",
    "            gh.avg_timeline(times, averaging),#[:-1],\n",
    "            gh.avg_timeline(vals.x, averaging)#[:-1]\n",
    "            * 148940000\n",
    "            * 1000000\n",
    "            * 0.000000000001,  # convert to global C in Gt\n",
    "            label=model_names[mf] + \" - X-matrix\",\n",
    "            color=model_cols[mf],            \n",
    "        )\n",
    "        ax.plot(            \n",
    "            gh.avg_timeline(times, averaging),#[:-1],\n",
    "            X_trendy_total\n",
    "            #gh.avg_timeline(X_trendy_total, averaging)\n",
    "            * 148940000\n",
    "            * 1000000\n",
    "            * 0.000000000001,  # convert to global C in Gt            \n",
    "            label=model_names[mf] + \" - X-trendy\",\n",
    "            color=add_cols[mf],\n",
    "            #linestyle=\"dashed\",\n",
    "        )\n",
    "        ax.plot(\n",
    "            gh.avg_timeline(times, averaging),#[:-1],\n",
    "            gh.avg_timeline(vals.x_c, averaging)#[:-1]\n",
    "            * 148940000\n",
    "            * 1000000\n",
    "            * 0.000000000001,  # convert to global C in Gt\n",
    "            label=model_names[mf] + \" - X_c-matrix\",\n",
    "            color=model_cols[mf],\n",
    "            linestyle=\"dashed\",\n",
    "        )\n",
    "        ax.plot(\n",
    "            gh.avg_timeline(times, averaging),#[:-1],            \n",
    "            X_c_trendy_total\n",
    "            #gh.avg_timeline(X_c_trendy_total, averaging)\n",
    "            * 148940000\n",
    "            * 1000000\n",
    "            * 0.000000000001,  # convert to global C in Gt\n",
    "            label=model_names[mf] + \" - X_c-trendy\",\n",
    "            color=add_cols[mf],\n",
    "            linestyle=\"dashed\",\n",
    "        )\n",
    "        \n",
    "        k += 1\n",
    "    ax.legend()\n",
    "    ax.set_title(\"Total Carbon (X) and Carbon Storage Capacity (X_c)\")\n",
    "    ax.set_ylabel(\"Gt C\")\n",
    "    ax.grid()\n",
    "    plt.ylim([-1000, 4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adc3e0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_u_trendy(\n",
    "    model_names,  # dictionary (folder name : model name)\n",
    "    test_arg_list,  # a list of test_args from all models involved\n",
    "    delta_t_val,  # model time step\n",
    "    model_cols,  # dictionary (folder name :color)\n",
    "    add_cols,\n",
    "    part,  # 0<part<1 to plot only a part of the whole timeling, e.g. 1 (whole timeline) or 0.1 (10%)\n",
    "    averaging,  # number of iterator steps over which to average results. 1 for no averaging\n",
    "    overlap=True,  # compute overlapping timeframe or plot whole duration for all models\n",
    "):\n",
    "    if (part < 0) | (part > 1):\n",
    "        raise Exception(\n",
    "            \"Invalid partitioning in plot_components_combined: use part between 0 and 1\"\n",
    "        )\n",
    "    model_folders = [(k) for k in model_names]\n",
    "    fig = plt.figure(figsize=(17, 8))\n",
    "    ax = fig.subplots(1, 1)\n",
    "    k = 0\n",
    "    for mf in model_folders:\n",
    "        itr = gh.traceability_iterator_instance(mf, test_arg_list[k], delta_t_val)\n",
    "        if overlap == True:\n",
    "            start_min, stop_max = gh.min_max_index(\n",
    "                test_arg_list[k],\n",
    "                delta_t_val,\n",
    "                *gh.t_min_tmax_overlap(test_arg_list, delta_t_val)\n",
    "            )\n",
    "        else:\n",
    "            start_min, stop_max = gh.min_max_index(\n",
    "                test_arg_list[k],\n",
    "                delta_t_val,\n",
    "                *gh.t_min_tmax_full(test_arg_list, delta_t_val)\n",
    "            )\n",
    "        # if we do not want the whole interval but look at a smaller part to observe the dynamics\n",
    "        start, stop = int(stop_max - (stop_max - start_min) * part), stop_max\n",
    "        times = (\n",
    "            gh.times_in_days_aD(test_arg_list[k], delta_t_val)[start:stop]\n",
    "            / gh.days_per_year()\n",
    "        )\n",
    "        vals = itr[start:stop]\n",
    "        # print(\"vals.x\")\n",
    "        # print(vals.x[0:240])\n",
    "        \n",
    "        ############## method from O'Sallivan et al. (2022)\n",
    "        cVeg_trendy=test_arg_list[k].svs.cVeg\n",
    "        if model_names[mf]==\"VISIT\":\n",
    "            cSoil_trendy=test_arg_list[k].svs.cLitter+test_arg_list[k].svs.cSoil\n",
    "        else:\n",
    "            cSoil_trendy=test_arg_list[k].svs.cSoil\n",
    "        rh_trendy=test_arg_list[k].svs.rh\n",
    "        npp_trendy=test_arg_list[k].dvs.npp\n",
    "        #npp_trendy_yearly=npp_sum(npp_trendy)\n",
    "        \n",
    "        delta_cVeg=np.zeros_like(cVeg_trendy)\n",
    "        for i in range (len(cVeg_trendy)-1):\n",
    "            delta_cVeg[i]=cVeg_trendy[i+1]-cVeg_trendy[i]\n",
    "    \n",
    "        delta_cSoil=np.zeros_like(cSoil_trendy)\n",
    "        for i in range (len(cSoil_trendy)-1):\n",
    "            delta_cSoil[i]=cSoil_trendy[i+1]-cSoil_trendy[i]    \n",
    "    \n",
    "        tau_v=cVeg_trendy/(npp_trendy-delta_cVeg)\n",
    "        X_c_v_trendy=tau_v*npp_trendy\n",
    "        #X_c_v_trendy_yearly=gh.avg_timeline(X_c_v_trendy,12)\n",
    "\n",
    "        f_vs=delta_cSoil+rh_trendy\n",
    "\n",
    "        tau_s=cSoil_trendy/rh_trendy\n",
    "        X_c_s_trendy=f_vs*tau_s\n",
    "        #X_c_s_trendy_yearly=gh.avg_timeline(X_c_s_trendy,12)\n",
    "\n",
    "        X_trendy_total=(cVeg_trendy+cSoil_trendy)[start//averaging//delta_t_val:stop//averaging//delta_t_val]#*148940000*1000000*0.000000000001\n",
    "        X_c_trendy_total=(X_c_v_trendy+X_c_s_trendy)[start//averaging//delta_t_val:stop//averaging//delta_t_val]#*148940000*1000000*0.000000000001 \n",
    "        u_trendy=npp_trendy[start//averaging//delta_t_val:stop//averaging//delta_t_val]\n",
    "#         print(str(mf)+\": \"+str(X_c_trendy_total.shape)+\" ; \"+str(X_trendy_total.shape))\n",
    "#         print (\"start: \"+str(start)+\" stop: \"+str(stop))\n",
    "#         print (npp_trendy)\n",
    "#         print (vals.u)\n",
    "        ###################\n",
    "        ax.plot(\n",
    "            gh.avg_timeline(times, averaging)[:-1],\n",
    "            gh.avg_timeline(vals.u, averaging)[:-1]\n",
    "            * 148940000\n",
    "            * 1000000\n",
    "            * 0.000000000001,  # convert to global C in Gt\n",
    "            label=model_names[mf] + \" - npp-matrix\",\n",
    "            color=model_cols[mf],            \n",
    "        )\n",
    "        ax.plot(            \n",
    "            gh.avg_timeline(times, averaging)[:-1],\n",
    "            u_trendy\n",
    "            #gh.avg_timeline(u_trendy, averaging)\n",
    "            * 148940000\n",
    "            * 1000000\n",
    "            * 0.000000000001,  # convert to global C in Gt            \n",
    "            label=model_names[mf] + \" - npp-trendy\",\n",
    "            color=add_cols[mf],\n",
    "        )\n",
    "    ax.legend()\n",
    "    ax.set_title(\"Carbon Input (NPP)\")\n",
    "    ax.set_ylabel(\"Gt C / day\")\n",
    "    ax.grid()\n",
    "    \n",
    "#     print(gh.avg_timeline(vals.u, averaging)\n",
    "#           * 148940000\n",
    "#           * 1000000\n",
    "#           * 0.000000000001,\n",
    "#          )\n",
    "#     print(gh.avg_timeline(u_trendy, averaging)\n",
    "#           * 148940000\n",
    "#           * 1000000\n",
    "#           * 0.000000000001,\n",
    "#          )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c2d43c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rt_trendy(\n",
    "    model_names,  # dictionary (folder name : model name)\n",
    "    test_arg_list,  # a list of test_args from all models involved\n",
    "    delta_t_val,  # model time step\n",
    "    model_cols,  # dictionary (folder name :color)\n",
    "    add_cols,\n",
    "    part,  # 0<part<1 to plot only a part of the whole timeling, e.g. 1 (whole timeline) or 0.1 (10%)\n",
    "    averaging,  # number of iterator steps over which to average results. 1 for no averaging\n",
    "    overlap=True,  # compute overlapping timeframe or plot whole duration for all models\n",
    "):\n",
    "    if (part < 0) | (part > 1):\n",
    "        raise Exception(\n",
    "            \"Invalid partitioning in plot_components_combined: use part between 0 and 1\"\n",
    "        )\n",
    "    model_folders = [(k) for k in model_names]\n",
    "    fig = plt.figure(figsize=(17, 8))\n",
    "    ax = fig.subplots(1, 1)\n",
    "    k = 0\n",
    "    for mf in model_folders:\n",
    "        itr = gh.traceability_iterator_instance(mf, test_arg_list[k], delta_t_val)\n",
    "        if overlap == True:\n",
    "            start_min, stop_max = gh.min_max_index(\n",
    "                test_arg_list[k],\n",
    "                delta_t_val,\n",
    "                *gh.t_min_tmax_overlap(test_arg_list, delta_t_val)\n",
    "            )\n",
    "        else:\n",
    "            start_min, stop_max = gh.min_max_index(\n",
    "                test_arg_list[k],\n",
    "                delta_t_val,\n",
    "                *gh.t_min_tmax_full(test_arg_list, delta_t_val)\n",
    "            )\n",
    "        # if we do not want the whole interval but look at a smaller part to observe the dynamics\n",
    "        start, stop = int(stop_max - (stop_max - start_min) * part), stop_max\n",
    "        times = (\n",
    "            gh.times_in_days_aD(test_arg_list[k], delta_t_val)[start:stop]\n",
    "            / gh.days_per_year()\n",
    "        )\n",
    "        vals = itr[start:stop]\n",
    "        # print(\"vals.x\")\n",
    "        # print(vals.x[0:240])\n",
    "        \n",
    "        ############## method from O'Sallivan et al. (2022)\n",
    "        cVeg_trendy=test_arg_list[k].svs.cVeg\n",
    "        if model_names[mf]==\"VISIT\":\n",
    "            cSoil_trendy=test_arg_list[k].svs.cLitter+test_arg_list[k].svs.cSoil\n",
    "        else:\n",
    "            cSoil_trendy=test_arg_list[k].svs.cSoil\n",
    "        rh_trendy=test_arg_list[k].svs.rh\n",
    "        npp_trendy=test_arg_list[k].dvs.npp\n",
    "        #npp_trendy_yearly=npp_sum(npp_trendy)\n",
    "        \n",
    "        delta_cVeg=np.zeros_like(cVeg_trendy)\n",
    "        for i in range (len(cVeg_trendy)-1):\n",
    "            delta_cVeg[i]=cVeg_trendy[i+1]-cVeg_trendy[i]\n",
    "    \n",
    "        delta_cSoil=np.zeros_like(cSoil_trendy)\n",
    "        for i in range (len(cSoil_trendy)-1):\n",
    "            delta_cSoil[i]=cSoil_trendy[i+1]-cSoil_trendy[i]    \n",
    "    \n",
    "        tau_v=cVeg_trendy/(npp_trendy-delta_cVeg)\n",
    "        X_c_v_trendy=tau_v*npp_trendy\n",
    "        #X_c_v_trendy_yearly=gh.avg_timeline(X_c_v_trendy,12)\n",
    "\n",
    "        f_vs=delta_cSoil+rh_trendy\n",
    "\n",
    "        tau_s=cSoil_trendy/rh_trendy\n",
    "        X_c_s_trendy=f_vs*tau_s\n",
    "        #X_c_s_trendy_yearly=gh.avg_timeline(X_c_s_trendy,12)\n",
    "\n",
    "        X_trendy_total=(cVeg_trendy+cSoil_trendy)[start//averaging//delta_t_val:stop//averaging//delta_t_val]#*148940000*1000000*0.000000000001\n",
    "        X_c_trendy_total=(X_c_v_trendy+X_c_s_trendy)[start//averaging//delta_t_val:stop//averaging//delta_t_val]#*148940000*1000000*0.000000000001 \n",
    "        u_trendy=npp_trendy[start//averaging//delta_t_val:stop//averaging//delta_t_val]\n",
    "        tau_trendy=(tau_v+tau_s)[start//averaging//delta_t_val:stop//averaging//delta_t_val]\n",
    "#         print(str(mf)+\": \"+str(X_c_trendy_total.shape)+\" ; \"+str(X_trendy_total.shape))\n",
    "#         print (\"start: \"+str(start)+\" stop: \"+str(stop))\n",
    "#         print (tau_trendy)\n",
    "#         print (vals.rt)\n",
    "        ###################\n",
    "        ax.plot(\n",
    "            gh.avg_timeline(times, averaging)[:-1],\n",
    "            gh.avg_timeline(vals.rt, averaging)[:-1],  # convert to global C in Gt\n",
    "            label=model_names[mf] + \" - rt-matrix\",\n",
    "            color=model_cols[mf],            \n",
    "        )\n",
    "        ax.plot(            \n",
    "            gh.avg_timeline(times, averaging)[:-1],\n",
    "            tau_trendy,\n",
    "            #gh.avg_timeline(u_trendy, averaging),  # convert to global C in Gt            \n",
    "            label=model_names[mf] + \" - tau-trendy\",\n",
    "            color=add_cols[mf],\n",
    "        )\n",
    "    ax.legend()\n",
    "    ax.set_title(\"Residense time / turnover time\")\n",
    "    ax.set_ylabel(\"years\")\n",
    "    ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c2ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ab90348",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_names_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_x_xc_trendy(model_names\u001b[38;5;241m=\u001b[39m\u001b[43mmodel_names_test\u001b[49m,\n\u001b[0;32m      2\u001b[0m                      delta_t_val\u001b[38;5;241m=\u001b[39mdelta_t_val,\n\u001b[0;32m      3\u001b[0m                      test_arg_list\u001b[38;5;241m=\u001b[39mtest_arg_list_test,\n\u001b[0;32m      4\u001b[0m                      model_cols\u001b[38;5;241m=\u001b[39mmodel_cols,\n\u001b[0;32m      5\u001b[0m                      add_cols\u001b[38;5;241m=\u001b[39madd_cols,\n\u001b[0;32m      6\u001b[0m                      part\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m      7\u001b[0m                      averaging\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m30\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mdelta_t_val,\n\u001b[0;32m      8\u001b[0m                      overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      9\u001b[0m                      )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_names_test' is not defined"
     ]
    }
   ],
   "source": [
    "plot_x_xc_trendy(model_names=model_names_test,\n",
    "                     delta_t_val=delta_t_val,\n",
    "                     test_arg_list=test_arg_list_test,\n",
    "                     model_cols=model_cols,\n",
    "                     add_cols=add_cols,\n",
    "                     part=1,\n",
    "                     averaging=12*30//delta_t_val,\n",
    "                     overlap=True\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c87fdf99",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_names_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_u_trendy(model_names\u001b[38;5;241m=\u001b[39m\u001b[43mmodel_names_test\u001b[49m,\n\u001b[0;32m      2\u001b[0m                      delta_t_val\u001b[38;5;241m=\u001b[39mdelta_t_val,\n\u001b[0;32m      3\u001b[0m                      test_arg_list\u001b[38;5;241m=\u001b[39mtest_arg_list_test,\n\u001b[0;32m      4\u001b[0m                      model_cols\u001b[38;5;241m=\u001b[39mmodel_cols,\n\u001b[0;32m      5\u001b[0m                      add_cols\u001b[38;5;241m=\u001b[39madd_cols,\n\u001b[0;32m      6\u001b[0m                      part\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m      7\u001b[0m                      averaging\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m30\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mdelta_t_val,\n\u001b[0;32m      8\u001b[0m                      overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      9\u001b[0m                      )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_names_test' is not defined"
     ]
    }
   ],
   "source": [
    "plot_u_trendy(model_names=model_names_test,\n",
    "                     delta_t_val=delta_t_val,\n",
    "                     test_arg_list=test_arg_list_test,\n",
    "                     model_cols=model_cols,\n",
    "                     add_cols=add_cols,\n",
    "                     part=1,\n",
    "                     averaging=12*30//delta_t_val,\n",
    "                     overlap=True\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22681ff4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_names_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_rt_trendy(model_names\u001b[38;5;241m=\u001b[39m\u001b[43mmodel_names_test\u001b[49m,\n\u001b[0;32m      2\u001b[0m                      delta_t_val\u001b[38;5;241m=\u001b[39mdelta_t_val,\n\u001b[0;32m      3\u001b[0m                      test_arg_list\u001b[38;5;241m=\u001b[39mtest_arg_list_test,\n\u001b[0;32m      4\u001b[0m                      model_cols\u001b[38;5;241m=\u001b[39mmodel_cols,\n\u001b[0;32m      5\u001b[0m                      add_cols\u001b[38;5;241m=\u001b[39madd_cols,\n\u001b[0;32m      6\u001b[0m                      part\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m      7\u001b[0m                      averaging\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m30\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mdelta_t_val,\n\u001b[0;32m      8\u001b[0m                      overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      9\u001b[0m                      )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_names_test' is not defined"
     ]
    }
   ],
   "source": [
    "plot_rt_trendy(model_names=model_names_test,\n",
    "                     delta_t_val=delta_t_val,\n",
    "                     test_arg_list=test_arg_list_test,\n",
    "                     model_cols=model_cols,\n",
    "                     add_cols=add_cols,\n",
    "                     part=1,\n",
    "                     averaging=12*30//delta_t_val,\n",
    "                     overlap=True\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bee06c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
